{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-07-08T16:55:09.163041Z",
     "iopub.status.busy": "2024-07-08T16:55:09.162616Z",
     "iopub.status.idle": "2024-07-08T16:55:10.320923Z",
     "shell.execute_reply": "2024-07-08T16:55:10.319731Z",
     "shell.execute_reply.started": "2024-07-08T16:55:09.162993Z"
    }
   },
   "source": [
    "### MOVIE RECOMMENDATION SYSTEM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In todayâ€™s technology-driven world, recommender systems are socially and economically critical for ensuring that individuals can make appropriate choices surrounding the content they engage with on a daily basis. One application where this is especially true surrounds movie content recommendations; where intelligent algorithms can help viewers find great titles from tens of thousands of options.\n",
    "\n",
    "...ever wondered how Netflix, Amazon Prime, Showmax, Disney and the likes somehow know what to recommend to you?\n",
    "...it's not just a guess drawn out of the hat. There is an algorithm behind it.\n",
    "\n",
    "With this context, we are challenging you to construct a recommendation algorithm based on content or collaborative filtering, capable of accurately predicting how a user will rate a movie they have not yet viewed based on their historical preferences.\n",
    "\n",
    "What value is achieved through building a functional recommender system?\n",
    "Providing an accurate and robust solution to this challenge has immense economic potential, with users of the system being exposed to content they would like to view or purchase - generating revenue and platform affinity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supplied Files\n",
    "genome_scores.csv - a score mapping the strength between movies and tag-related properties.\n",
    "\n",
    "genome_tags.csv - user assigned tags for genome-related scores\n",
    "\n",
    "imdb_data.csv - Additional movie metadata scraped from IMDB using the links.csv file.\n",
    "\n",
    "links.csv - File providing a mapping between a MovieLens ID and associated IMDB and TMDB IDs.\n",
    "\n",
    "sample_submission.csv - Sample of the submission format for the hackathon.\n",
    "\n",
    "tags.csv - User assigned for the movies within the dataset.\n",
    "\n",
    "test.csv - The test split of the dataset. Contains user and movie IDs with no rating data.\n",
    "\n",
    "train.csv - The training split of the dataset. Contains user and movie IDs with associated rating data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-08T17:01:06.402369Z",
     "iopub.status.busy": "2024-07-08T17:01:06.401926Z",
     "iopub.status.idle": "2024-07-08T17:01:21.970648Z",
     "shell.execute_reply": "2024-07-08T17:01:21.969494Z",
     "shell.execute_reply.started": "2024-07-08T17:01:06.402334Z"
    }
   },
   "outputs": [],
   "source": [
    "ratings_df = pd.read_csv('/kaggle/input/alx-movie-recommendation-project-2024/train.csv')\n",
    "movies_df = pd.read_csv('/kaggle/input/alx-movie-recommendation-project-2024/movies.csv')\n",
    "imdb_df = pd.read_csv('/kaggle/input/alx-movie-recommendation-project-2024/imdb_data.csv')\n",
    "test_df = pd.read_csv('/kaggle/input/alx-movie-recommendation-project-2024/test.csv')\n",
    "links_df = pd.read_csv('/kaggle/input/alx-movie-recommendation-project-2024/links.csv')\n",
    "tags = pd.read_csv('/kaggle/input/alx-movie-recommendation-project-2024/tags.csv')\n",
    "genome_scores = pd.read_csv('/kaggle/input/alx-movie-recommendation-project-2024/genome_scores.csv')\n",
    "genome_tags = pd.read_csv('/kaggle/input/alx-movie-recommendation-project-2024/genome_tags.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-08T17:01:32.127175Z",
     "iopub.status.busy": "2024-07-08T17:01:32.126450Z",
     "iopub.status.idle": "2024-07-08T17:01:32.141940Z",
     "shell.execute_reply": "2024-07-08T17:01:32.140652Z",
     "shell.execute_reply.started": "2024-07-08T17:01:32.127140Z"
    }
   },
   "outputs": [],
   "source": [
    "# Install packages here\n",
    "# Packages for data processing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from sklearn import preprocessing\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import re\n",
    "from scipy.sparse import csr_matrix\n",
    "import scipy as sp\n",
    "\n",
    "\n",
    "# Packages for visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "# Packages for modeling\n",
    "from surprise import Reader\n",
    "from surprise import Dataset\n",
    "from surprise import KNNWithMeans\n",
    "from surprise import KNNBasic\n",
    "from surprise.model_selection import cross_validate\n",
    "from surprise.model_selection import GridSearchCV\n",
    "from surprise import SVD\n",
    "from surprise import SVDpp\n",
    "from surprise import NMF\n",
    "from surprise import SlopeOne\n",
    "from surprise import CoClustering\n",
    "import heapq\n",
    "\n",
    "# Packages for model evaluation\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from time import time\n",
    "\n",
    "# Package to suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Packages for saving models\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-08T17:01:39.893248Z",
     "iopub.status.busy": "2024-07-08T17:01:39.892807Z",
     "iopub.status.idle": "2024-07-08T17:01:39.939824Z",
     "shell.execute_reply": "2024-07-08T17:01:39.938710Z",
     "shell.execute_reply.started": "2024-07-08T17:01:39.893213Z"
    }
   },
   "outputs": [],
   "source": [
    "movies_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-08T17:01:42.245888Z",
     "iopub.status.busy": "2024-07-08T17:01:42.245433Z",
     "iopub.status.idle": "2024-07-08T17:01:42.273206Z",
     "shell.execute_reply": "2024-07-08T17:01:42.271833Z",
     "shell.execute_reply.started": "2024-07-08T17:01:42.245849Z"
    }
   },
   "outputs": [],
   "source": [
    "movies_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-08T17:02:05.582524Z",
     "iopub.status.busy": "2024-07-08T17:02:05.582077Z",
     "iopub.status.idle": "2024-07-08T17:02:05.720709Z",
     "shell.execute_reply": "2024-07-08T17:02:05.719449Z",
     "shell.execute_reply.started": "2024-07-08T17:02:05.582489Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Train: \")\n",
    "print(str(ratings_df.isnull().sum()))\n",
    "print(\"************\")\n",
    "print(\"Test: \")\n",
    "print(str(test_df.isnull().sum()))\n",
    "print(\"************\")\n",
    "print(\"Movies: \")\n",
    "print(str(movies_df.isnull().sum()))\n",
    "print(\"************\")\n",
    "print(\"Links: \")\n",
    "print(str(links_df.isnull().sum()))\n",
    "print(\"************\")\n",
    "print(\"IMDB: \")\n",
    "print(str(imdb_df.isnull().sum()))\n",
    "print(\"************\")\n",
    "print(\"Genome scores: \")\n",
    "print(str(genome_scores.isnull().sum()))\n",
    "print(\"************\")\n",
    "print(\"Genome tags: \")\n",
    "print(str(genome_tags.isnull().sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-08T17:02:42.717583Z",
     "iopub.status.busy": "2024-07-08T17:02:42.717133Z",
     "iopub.status.idle": "2024-07-08T17:02:43.079859Z",
     "shell.execute_reply": "2024-07-08T17:02:43.078551Z",
     "shell.execute_reply.started": "2024-07-08T17:02:42.717551Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create dataframe containing only the movieId and genres\n",
    "movies_genres = pd.DataFrame(movies_df[['movieId', 'genres']],\n",
    "                             columns=['movieId', 'genres'])\n",
    "\n",
    "# Split genres seperated by \"|\" and create a list containing the genres allocated to each movie\n",
    "movies_genres.genres = movies_genres.genres.apply(lambda x: x.split('|'))\n",
    "\n",
    "# Create expanded dataframe where each movie-genre combination is in a seperate row\n",
    "movies_genres = pd.DataFrame([(tup.movieId, d) for tup in movies_genres.itertuples() for d in tup.genres],\n",
    "                             columns=['movieId', 'genres'])\n",
    "\n",
    "movies_genres.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-08T17:02:45.174988Z",
     "iopub.status.busy": "2024-07-08T17:02:45.174575Z",
     "iopub.status.idle": "2024-07-08T17:02:45.818166Z",
     "shell.execute_reply": "2024-07-08T17:02:45.816816Z",
     "shell.execute_reply.started": "2024-07-08T17:02:45.174958Z"
    }
   },
   "outputs": [],
   "source": [
    "plot = plt.figure(figsize=(15, 10))\n",
    "plt.title('Most common genres\\n', fontsize=20)\n",
    "sns.countplot(y=\"genres\", data=movies_genres,\n",
    "              order=movies_genres['genres'].value_counts(ascending=False).index,\n",
    "              palette='Reds_r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Stage 1: Data Preparation***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-08T17:07:39.407371Z",
     "iopub.status.busy": "2024-07-08T17:07:39.406865Z",
     "iopub.status.idle": "2024-07-08T17:07:48.349908Z",
     "shell.execute_reply": "2024-07-08T17:07:48.348633Z",
     "shell.execute_reply.started": "2024-07-08T17:07:39.407339Z"
    }
   },
   "outputs": [],
   "source": [
    "# Sample data for efficiency (use 10%)\n",
    "ratings_df = ratings_df.sample(frac=0.1, random_state=42)\n",
    "\n",
    "# Merge genome_scores with genome_tags to get tag names\n",
    "genome_scores = genome_scores.merge(genome_tags, on='tagId')\n",
    "\n",
    "# Create a pivot table where rows are movies and columns are tags, values are relevance scores\n",
    "movie_tag_matrix = genome_scores.pivot_table(index='movieId', columns='tag', values='relevance', fill_value=0)\n",
    "\n",
    "# Normalize the movie_tag_matrix\n",
    "scaler = StandardScaler()\n",
    "movie_tag_matrix_scaled = scaler.fit_transform(movie_tag_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***ANALYSIS 1(PCA)***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-08T17:08:15.918571Z",
     "iopub.status.busy": "2024-07-08T17:08:15.918127Z",
     "iopub.status.idle": "2024-07-08T17:08:19.200883Z",
     "shell.execute_reply": "2024-07-08T17:08:19.199925Z",
     "shell.execute_reply.started": "2024-07-08T17:08:15.918536Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "# Apply PCA\n",
    "pca = PCA(n_components=50)\n",
    "movie_tag_matrix_pca = pca.fit_transform(movie_tag_matrix_scaled)\n",
    "\n",
    "# Create a DataFrame for the PCA components\n",
    "movie_tag_pca_df = pd.DataFrame(movie_tag_matrix_pca, index=movie_tag_matrix.index)\n",
    "\n",
    "# Merge genres with ratings\n",
    "movies_df = movies_df[['movieId', 'genres']]\n",
    "ratings_with_genres = ratings_df.merge(movies_df, on='movieId')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ***ANALYSIS 2 (HYPER PARAMETER TUNING)***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-08T17:09:05.544339Z",
     "iopub.status.busy": "2024-07-08T17:09:05.543938Z",
     "iopub.status.idle": "2024-07-08T17:18:40.304597Z",
     "shell.execute_reply": "2024-07-08T17:18:40.303280Z",
     "shell.execute_reply.started": "2024-07-08T17:09:05.544309Z"
    }
   },
   "outputs": [],
   "source": [
    "from surprise.model_selection import train_test_split, GridSearchCV\n",
    "# Define the Reader and Dataset\n",
    "reader = Reader(rating_scale=(0.5, 5.0))\n",
    "data = Dataset.load_from_df(ratings_with_genres[['userId', 'movieId', 'rating']], reader)\n",
    "\n",
    "# Split the data into training and test sets\n",
    "trainset, testset = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define SVD model\n",
    "svd = SVD()\n",
    "\n",
    "# Hyperparameter tuning with Grid Search\n",
    "param_grid = {\n",
    "    'n_epochs': [20, 30],\n",
    "    'lr_all': [0.002, 0.005],\n",
    "    'reg_all': [0.4, 0.6]\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(SVD, param_grid, measures=['rmse'], cv=3)\n",
    "gs.fit(data)\n",
    "\n",
    "# Best SVD model\n",
    "best_svd = gs.best_estimator['rmse']\n",
    "print(f\"Best RMSE: {gs.best_score['rmse']} with parameters: {gs.best_params['rmse']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-08T17:27:23.203878Z",
     "iopub.status.busy": "2024-07-08T17:27:23.203400Z",
     "iopub.status.idle": "2024-07-08T17:39:49.172416Z",
     "shell.execute_reply": "2024-07-08T17:39:49.171147Z",
     "shell.execute_reply.started": "2024-07-08T17:27:23.203847Z"
    }
   },
   "outputs": [],
   "source": [
    "# Train the best model on the full trainset\n",
    "trainset = data.build_full_trainset()\n",
    "best_svd.fit(trainset)\n",
    "\n",
    "# Function to predict rating for a user-movie pair\n",
    "def predict_rating(user_id, movie_id):\n",
    "    prediction = best_svd.predict(user_id, movie_id)\n",
    "    return prediction.est\n",
    "\n",
    "# Generate predictions for test set\n",
    "test_df['rating'] = test_df.apply(lambda x: predict_rating(x['userId'], x['movieId']), axis=1)\n",
    "\n",
    "# Calculate RMSE for test predictions\n",
    "predictions = [best_svd.predict(row['userId'], row['movieId']).est for _, row in test_df.iterrows()]\n",
    "true_ratings = [row['rating'] for _, row in test_df.iterrows()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-08T17:42:37.363359Z",
     "iopub.status.busy": "2024-07-08T17:42:37.362908Z",
     "iopub.status.idle": "2024-07-08T17:44:26.204947Z",
     "shell.execute_reply": "2024-07-08T17:44:26.203899Z",
     "shell.execute_reply.started": "2024-07-08T17:42:37.363328Z"
    }
   },
   "outputs": [],
   "source": [
    "# Prepare submission DataFrame\n",
    "submission = test_df[['userId', 'movieId', 'rating']]\n",
    "submission['Id'] = submission.apply(lambda x: f\"{int(x['userId'])}_{int(x['movieId'])}\", axis=1)\n",
    "submission = submission[['Id', 'rating']]\n",
    "\n",
    "# Save submission to CSV\n",
    "submission.to_csv('movie_recommender.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 8778365,
     "sourceId": 81285,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30732,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
